{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MEMBER_TOKEN = os.getenv(\"MEMBER_AUTH_TOKEN\")\n",
    "API_BASE_URL = os.getenv(\"XPENSIFY_BASE_URL\")\n",
    "\n",
    "IMAGE_FOLDER_PATH = \"/receipts\"\n",
    "CLAIM_TITLE = \"Team Expenses\"\n",
    "PROJECT_NAME = \"Default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_setup_agent():\n",
    "    \"\"\"Fetches currencies, expense types, and projects.\"\"\"\n",
    "    print(\"-> Setup Agent: Fetching required data...\")\n",
    "    headers = {'Authorization': f'Bearer {MEMBER_TOKEN}'}\n",
    "    \n",
    "    try:\n",
    "        print(\"üëâ Fetching:\", repr(API_BASE_URL))\n",
    "        # Fetch Currency Types\n",
    "        currencies_res = requests.get(f\"{API_BASE_URL}/currency_types\", headers=headers)\n",
    "        currencies_res.raise_for_status()\n",
    "        currencies = currencies_res.json()['data']\n",
    "        print(f\"-> Setup Agent: Found {len(currencies)} currencies.\")\n",
    "        \n",
    "        # Fetch Expense Types\n",
    "        expense_types_res = requests.get(f\"{API_BASE_URL}/expense_type/?is_active=True\", headers=headers)\n",
    "        expense_types_res.raise_for_status()\n",
    "        expense_types = expense_types_res.json()['data']\n",
    "        print(f\"-> Setup Agent: Found {len(expense_types)} active expense types.\")\n",
    "        \n",
    "        # Fetch Projects\n",
    "        projects_res = requests.get(f\"{API_BASE_URL}/timesheets/\", headers=headers)\n",
    "        projects_res.raise_for_status()\n",
    "        projects = projects_res.json()['timesheetNames']\n",
    "        print(f\"-> Setup Agent: Found {len(projects)} projects.\")\n",
    "        \n",
    "        return {\"currencies\": currencies, \"expense_types\": expense_types, \"projects\": projects}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Setup Agent Error: Failed to fetch data. {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extraction_agent(base64_image_data, mime_type, setup_data):\n",
    "    \"\"\"Analyzes the bill image using Gemini AI and returns structured data.\"\"\"\n",
    "    print(\"\\n-> Extraction Agent: Analyzing bill with Gemini AI...\")\n",
    "\n",
    "    if not GEMINI_API_KEY:\n",
    "        raise ValueError(\"GEMINI_API_KEY is not set in your .env file.\")\n",
    "\n",
    "    # Get a list of valid expense type names for the prompt\n",
    "    valid_expense_type_names = [et['name'] for et in setup_data['expense_types']]\n",
    "    \n",
    "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "    system_prompt = f\"\"\"You are an intelligent expense processing agent. Analyze the provided bill image.\n",
    "    1. Extract the following fields: date, vendor, amount (as a number), currency (the 3-letter symbol, e.g., USD, EUR, INR).\n",
    "    2. For the date, find the primary date of the transaction and format it as YYYY-MM-DD.\n",
    "    3. Classify the expense into ONE of the following categories: {json.dumps(valid_expense_type_names)}.\n",
    "    4. Return the result as a single, valid JSON object with the keys: \"date\", \"vendor\", \"amount\", \"currency\", and \"expenseType\".\n",
    "    If a value cannot be determined, set it to an empty string or null for amount.\"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [{\n",
    "            \"parts\": [\n",
    "                {\"text\": system_prompt},\n",
    "                {\"inlineData\": {\"mimeType\": mime_type, \"data\": base64_image_data}}\n",
    "            ]\n",
    "        }],\n",
    "        \"generationConfig\": {\"responseMimeType\": \"application/json\"}\n",
    "    }\n",
    "    \n",
    "    response = requests.post(api_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    part = result.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0]\n",
    "    \n",
    "    if \"text\" in part:\n",
    "        extracted_data = json.loads(part[\"text\"])\n",
    "        print(\"-> Extraction Agent: Successfully extracted data.\")\n",
    "        return extracted_data\n",
    "    else:\n",
    "        raise ValueError(f\"Could not parse AI response: {json.dumps(result, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_claim():\n",
    "    \"\"\"Creates a new claim and returns its PK.\"\"\"\n",
    "    print(\"\\n-> Submission Agent: Creating new claim...\")\n",
    "    headers = {'Authorization': f'Bearer {MEMBER_TOKEN}'}\n",
    "    params = {'role': 'User'}\n",
    "    create_claim_res = requests.post(f\"{API_BASE_URL}/claim\", headers=headers, params=params,json={})\n",
    "    create_claim_res.raise_for_status()\n",
    "    claim_data = create_claim_res.json()\n",
    "    claim_pk = claim_data['claim_pk']\n",
    "    print(f\"Successfully created claim with ID: {claim_pk}\")\n",
    "    return claim_pk\n",
    "\n",
    "def update_claim_title(claim_pk, title):\n",
    "    \"\"\"Updates the title of an existing claim.\"\"\"\n",
    "    print(f\"-> Submission Agent: Updating title for claim {claim_pk}...\")\n",
    "    headers = {'Authorization': f'Bearer {MEMBER_TOKEN}'}\n",
    "    params = {'role': 'User'}\n",
    "    update_title_res = requests.put(f\"{API_BASE_URL}/claim/{claim_pk}\", headers=headers, params=params, json={'title': title})\n",
    "    update_title_res.raise_for_status()\n",
    "    print(f\"Successfully set title to: '{title}'\")\n",
    "\n",
    "def add_expense_to_claim(claim_pk, extracted_data, setup_data, image_data, image_path, mime_type):\n",
    "    \"\"\"Adds a single expense and its corresponding bill to an existing claim.\"\"\"\n",
    "    print(f\"\\n-> Submission Agent: Adding expense from '{os.path.basename(image_path)}' to claim {claim_pk}...\")\n",
    "    headers = {'Authorization': f'Bearer {MEMBER_TOKEN}'}\n",
    "    params = {'role': 'User'}\n",
    "\n",
    "    try:\n",
    "        # Step A: Prepare and create the expense\n",
    "        print(f\"  [Sub-step A] Creating expense...\")\n",
    "        expense_type_id = next((et['id'] for et in setup_data['expense_types'] if et['name'] == extracted_data['expenseType']), None)\n",
    "        project_id = next((p['projectId'] for p in setup_data['projects'] if p['projectName'] == PROJECT_NAME), None)\n",
    "        \n",
    "        if not expense_type_id: raise ValueError(f\"Could not find ID for expense type: {extracted_data['expenseType']}\")\n",
    "        if not project_id: raise ValueError(f\"Could not find ID for project: {PROJECT_NAME}\")\n",
    "            \n",
    "        expense_payload = {\n",
    "            \"amount\": extracted_data['amount'],\n",
    "            \"currency_type_symbol\": extracted_data['currency'],\n",
    "            \"date_of_expense\": f\"{extracted_data['date']}T00:00:00.000Z\",\n",
    "            \"expense_type_id\": expense_type_id,\n",
    "            \"project_id\": project_id,\n",
    "            \"user_comment\": \"\",\n",
    "            \"vendor\": extracted_data['vendor']\n",
    "        }\n",
    "        print(\"  Expense Payload:\")\n",
    "        print(json.dumps(expense_payload, indent=2))\n",
    "        \n",
    "        create_expense_res = requests.post(f\"{API_BASE_URL}/claim/{claim_pk}/expense\", headers=headers, params=params, json=expense_payload)\n",
    "        create_expense_res.raise_for_status()\n",
    "        expense_res_data = create_expense_res.json()\n",
    "        expense_id = expense_res_data['id']\n",
    "        print(f\"  Successfully created expense with ID: {expense_id}\")\n",
    "        \n",
    "        # Step B: Upload the bill image\n",
    "        print(f\"  [Sub-step B] Uploading bill for expense {expense_id}...\")\n",
    "        files = {'file': (os.path.basename(image_path), image_data, mime_type)}\n",
    "        upload_bill_res = requests.post(f\"{API_BASE_URL}/claim/{claim_pk}/expense/{expense_id}/bill\", headers=headers, params=params, files=files)\n",
    "        upload_bill_res.raise_for_status()\n",
    "        print(f\"  Successfully uploaded bill. Status Code: {upload_bill_res.status_code}\")\n",
    "        print(f\"  -> Finished processing '{os.path.basename(image_path)}'.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Submission Agent Error for '{os.path.basename(image_path)}': API call failed. {e}\")\n",
    "        if e.response is not None:\n",
    "            print(f\"Response Body: {e.response.text}\")\n",
    "        raise  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f59dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(os.getcwd())\n",
    "    \"\"\"Main function to orchestrate the expense claim process.\"\"\"\n",
    "    try:\n",
    "        if not MEMBER_TOKEN or not GEMINI_API_KEY:\n",
    "            raise ValueError(\"MEMBER_TOKEN and GEMINI_API_KEY must be set in the .env file.\")\n",
    "        \n",
    "        # Find all images in the specified folder\n",
    "        print(f\"-> Orchestrator: Searching for images in '{IMAGE_FOLDER_PATH}'...\")\n",
    "        if not os.path.isdir(IMAGE_FOLDER_PATH):\n",
    "            raise FileNotFoundError(f\"The specified image folder does not exist: {IMAGE_FOLDER_PATH}\")\n",
    "\n",
    "        supported_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\"]\n",
    "        image_paths = []\n",
    "        for ext in supported_extensions:\n",
    "            image_paths.extend(glob.glob(os.path.join(IMAGE_FOLDER_PATH, ext)))\n",
    "\n",
    "        if not image_paths:\n",
    "            raise FileNotFoundError(f\"No image files (.jpg, .jpeg, .png) found in '{IMAGE_FOLDER_PATH}'.\")\n",
    "        \n",
    "        print(f\"-> Orchestrator: Found {len(image_paths)} images to process.\")\n",
    "        \n",
    "        # 1. Run Setup Agent once to get all required API data\n",
    "        setup_data = run_setup_agent()\n",
    "        \n",
    "        # 2. Create a single new claim to house all expenses\n",
    "        claim_pk = create_new_claim()\n",
    "        update_claim_title(claim_pk, CLAIM_TITLE)\n",
    "\n",
    "        # 3. Loop through each image, extract data, and add as an expense to the claim\n",
    "        total_expenses = len(image_paths)\n",
    "        for index, current_image_path in enumerate(image_paths):\n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "            print(f\"Processing Expense {index + 1} of {total_expenses}: {os.path.basename(current_image_path)}\")\n",
    "            print(\"-\"*50)\n",
    "\n",
    "            # Ingestion: Read and encode the file for the current expense.\n",
    "            with open(current_image_path, \"rb\") as image_file:\n",
    "                image_data = image_file.read()\n",
    "            base64_image_data = base64.b64encode(image_data).decode('utf-8')\n",
    "            \n",
    "            file_extension = os.path.splitext(current_image_path)[1].lower()\n",
    "            mime_type = 'image/jpeg' if file_extension in ['.jpeg', '.jpg'] else 'image/png'\n",
    "\n",
    "            # Run Extraction Agent for the current bill.\n",
    "            extracted_data = run_extraction_agent(base64_image_data, mime_type, setup_data)\n",
    "            print(\"\\n--- Extracted Data from AI ---\")\n",
    "            print(json.dumps(extracted_data, indent=2))\n",
    "\n",
    "            # Add the extracted expense to our claim.\n",
    "            add_expense_to_claim(claim_pk, extracted_data, setup_data, image_data, current_image_path, mime_type)\n",
    "        \n",
    "        # 4. Final Output\n",
    "        final_url = f\"https://qa2-xpensify.sahaj.ai:8443/user/claims/{claim_pk}/expenses\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"‚úÖ All {total_expenses} expenses processed successfully under claim {claim_pk}!\")\n",
    "        print(f\"View your claim here: {final_url}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"\\n‚ùå An error occurred during the orchestration: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
